{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling the `hpctoolkit_dataframe` itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "import line_profiler\n",
    "\n",
    "import hpctoolkit_dataframe\n",
    "from hpctoolkit_dataframe import HPCtoolkitDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test/data/experiment2.xml: percentage column candidates CPUTIME (usec):['Mean (I)', 'Sum (I)'] not found, trying ['PAPI_MEM_WCY']:['Mean (I)', 'Sum (I)']\n"
     ]
    }
   ],
   "source": [
    "profiler = line_profiler.LineProfiler()\n",
    "profiler.add_module(hpctoolkit_dataframe)\n",
    "profiler.enable()\n",
    "\n",
    "df1 = HPCtoolkitDataFrame(path=pathlib.Path('.', 'test', 'data', 'experiment1.xml'), max_depth=None)\n",
    "df2 = HPCtoolkitDataFrame(path=pathlib.Path('.', 'test', 'data', 'experiment2.xml'), max_depth=None)\n",
    "\n",
    "profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.enable()\n",
    "\n",
    "hot_path1 = df1.hot_path(threshold=0.01)\n",
    "hot_path2 = df2.hot_path(threshold=0.01)\n",
    "\n",
    "profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.enable()\n",
    "\n",
    "df1.compact\n",
    "df2.compact\n",
    "\n",
    "profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profiler.enable()\n",
    "\n",
    "df1.flame_graph()\n",
    "df2.flame_graph(column='PAPI_MEM_WCY:Mean (I)')\n",
    "\n",
    "profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 4.35858 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: __init__ at line 154\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   154                                               def __init__(self, *args,\n",
      "   155                                                            path: pathlib.Path = None, max_depth: t.Optional[int] = None, **kwargs):\n",
      "   156      3811      14992.0      3.9      0.3          if path is None:\n",
      "   157      3809      82964.0     21.8      1.9              super().__init__(*args, **kwargs)\n",
      "   158      3809      12837.0      3.4      0.3              return\n",
      "   159         2         34.0     17.0      0.0          self._db_path = path\n",
      "   160                                           \n",
      "   161         2     257708.0 128854.0      5.9          profile_data = _read_xml(path).find('./SecCallPathProfile')\n",
      "   162         2         35.0     17.5      0.0          _LOG.info('%s: %s', path, profile_data.attrib['n'])\n",
      "   163                                           \n",
      "   164         2         68.0     34.0      0.0          metrics = profile_data.find('./SecHeader/MetricTable')\n",
      "   165         2         39.0     19.5      0.0          _LOG.debug('%s: %s', path, [(_, _.attrib) for _ in metrics])\n",
      "   166         2         93.0     46.5      0.0          self._metrics_by_id = {int(_.attrib['i']): _.attrib['n'] for _ in metrics}\n",
      "   167         2       1440.0    720.0      0.0          _LOG.info('%s: %s', path, pprint.pformat(self._metrics_by_id))\n",
      "   168                                           \n",
      "   169         2       2676.0   1338.0      0.1          self._metrics_formulas = _derive_metrics_formulas(metrics)\n",
      "   170         2       5747.0   2873.5      0.1          _LOG.info('%s: %s', path, pprint.pformat(self._metrics_formulas))\n",
      "   171                                           \n",
      "   172         2         79.0     39.5      0.0          modules = profile_data.find('./SecHeader/LoadModuleTable')\n",
      "   173         2         23.0     11.5      0.0          _LOG.debug('%s: %s', path, [(_, _.attrib) for _ in modules])\n",
      "   174         2        472.0    236.0      0.0          self._modules_by_id = {int(_.attrib['i']): pathlib.Path(_.attrib['n']) for _ in modules}\n",
      "   175         2        889.0    444.5      0.0          _LOG.info('%s: %s', path, pprint.pformat(self._modules_by_id))\n",
      "   176                                           \n",
      "   177         2         76.0     38.0      0.0          files = profile_data.find('./SecHeader/FileTable')\n",
      "   178         2         96.0     48.0      0.0          _LOG.debug('%s: %s', path, [(_, _.attrib) for _ in files])\n",
      "   179         2       4324.0   2162.0      0.1          self._files_by_id = {int(_.attrib['i']): pathlib.Path(_.attrib['n']) for _ in files}\n",
      "   180         2       6865.0   3432.5      0.2          _LOG.info('%s: %s', path, pprint.pformat(self._files_by_id))\n",
      "   181                                           \n",
      "   182         2         77.0     38.5      0.0          procedures = profile_data.find('./SecHeader/ProcedureTable')\n",
      "   183         2        243.0    121.5      0.0          _LOG.debug('%s: %s', path, [(_, _.attrib) for _ in procedures])\n",
      "   184         2        396.0    198.0      0.0          self._procedures_by_id = {int(_.attrib['i']): _.attrib['n'] for _ in procedures}\n",
      "   185         2      16510.0   8255.0      0.4          _LOG.info('%s: %s', path, pprint.pformat(self._procedures_by_id))\n",
      "   186                                           \n",
      "   187         2         64.0     32.0      0.0          measurements = profile_data.find('./SecCallPathProfileData')\n",
      "   188         2         27.0     13.5      0.0          _LOG.debug('%s: %s', path, [(_, _.attrib) for _ in measurements])\n",
      "   189                                           \n",
      "   190         2         24.0     12.0      0.0          columns = [metric for _, metric in sorted(self._metrics_by_id.items())]\n",
      "   191                                           \n",
      "   192                                                   # customize meanings of columns\n",
      "   193         2       1443.0    721.5      0.0          percentage_column = self._determine_percentage_column_base(columns)\n",
      "   194                                                   compact_columns = [\n",
      "   195         2          7.0      3.5      0.0              percentage_column + suffix\n",
      "   196         2         12.0      6.0      0.0              for suffix in self._compact_column_suffixes]\n",
      "   197                                           \n",
      "   198         2          9.0      4.5      0.0          columns += _LOCATION_COLUMNS\n",
      "   199         2          8.0      4.0      0.0          compact_columns += _COMPACT_LOCATION_COLUMNS\n",
      "   200                                           \n",
      "   201                                                   self._meaningful_columns = {\n",
      "   202         2          6.0      3.0      0.0              'percentage': percentage_column,\n",
      "   203         2          8.0      4.0      0.0              'hot_path': percentage_column + self._hot_path_column_suffix,\n",
      "   204         2         27.0     13.5      0.0              'compact': compact_columns}\n",
      "   205                                           \n",
      "   206         2    3892812.0 1946406.0     89.3          rows = self._add_measurements(measurements, max_depth=max_depth)\n",
      "   207         2       2095.0   1047.5      0.0          index = [_['id'] for _ in rows]\n",
      "   208         2        204.0    102.0      0.0          assert len(index) == len(set(index)), index\n",
      "   209         2      42698.0  21349.0      1.0          super().__init__(data=rows, index=index, columns=columns)\n",
      "   210         2       6165.0   3082.5      0.1          self._fix_root_measurement()\n",
      "   211         2       4171.0   2085.5      0.1          self._add_percentage_columns()\n",
      "   212                                           \n",
      "   213         2         72.0     36.0      0.0          assert self._meaningful_columns['hot_path'] in self.columns, \\\n",
      "   214                                                       (self._meaningful_columns['hot_path'], self.columns)\n",
      "   215         2         44.0     22.0      0.0          assert all(_ in self.columns for _ in compact_columns), \\\n",
      "   216                                                       (compact_columns, self.columns)\n",
      "\n",
      "Total time: 0.579164 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: _evaluate_measurements_data at line 218\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   218                                               def _evaluate_measurements_data(self, data: dict) -> dict:\n",
      "   219      6308       4623.0      0.7      0.8          processed_data = {}\n",
      "   220    135781     125289.0      0.9     21.6          for column, entry in data.items():\n",
      "   221    129473      87696.0      0.7     15.1              if column not in self._metrics_formulas:\n",
      "   222     22574      13828.0      0.6      2.4                  processed_data[column] = entry\n",
      "   223     22574      12471.0      0.6      2.2                  continue\n",
      "   224    106899      75643.0      0.7     13.1              formula_code, formula = self._metrics_formulas[column]\n",
      "   225    106899      59096.0      0.6     10.2              try:\n",
      "   226    106899     197037.0      1.8     34.0                  processed_data[column] = formula(self, data)\n",
      "   227                                                       except ValueError as error:\n",
      "   228                                                           raise ValueError(\n",
      "   229                                                               '{}: error while evaluating \"\"\"{}\"\"\" to compute \"{}\" in row {}'\n",
      "   230                                                               .format(self._db_path, formula_code, column, data)) from error\n",
      "   231      6308       3481.0      0.6      0.6          return processed_data\n",
      "\n",
      "Total time: 2.40146 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: _add_measurements at line 233\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   233                                               def _add_measurements(self, measurements: ET.Element, location: t.Dict[str, t.Any] = None, *,\n",
      "   234                                                                     max_depth: t.Optional[int] = None,\n",
      "   235                                                                     add_local: bool = True) -> t.List[pd.Series]:\n",
      "   236                                                   # split measurements into M and non-M items\n",
      "   237      7524      10714.0      1.4      0.4          local_measurements = {}\n",
      "   238      7524       9929.0      1.3      0.4          nonlocal_measurements = []\n",
      "   239    162759     229873.0      1.4      9.6          for measurement in measurements:\n",
      "   240    155235     217371.0      1.4      9.1              if measurement.tag != 'M':\n",
      "   241      7522      11445.0      1.5      0.5                  nonlocal_measurements.append(measurement)\n",
      "   242    147713     190579.0      1.3      7.9              elif add_local:\n",
      "   243                                                           local_measurements[self._metrics_by_id[int(measurement.attrib['n'])]] = \\\n",
      "   244    129473     321758.0      2.5     13.4                      float(measurement.attrib['v'])\n",
      "   245                                           \n",
      "   246      7524      10215.0      1.4      0.4          if location is None:\n",
      "   247         2          4.0      2.0      0.0              location = {'line': 0, 'id': -1, 'callpath': (), 'type': 'root'}\n",
      "   248                                           \n",
      "   249      7524       9866.0      1.3      0.4          if add_local:\n",
      "   250      6308     911488.0    144.5     38.0              local_measurements = self._evaluate_measurements_data(local_measurements)\n",
      "   251      6308      12823.0      2.0      0.5              local_measurements.update(location)\n",
      "   252      6308       9154.0      1.5      0.4              rows = [local_measurements]\n",
      "   253                                                   else:\n",
      "   254      1216       1661.0      1.4      0.1              rows = []\n",
      "   255                                           \n",
      "   256      7524      10189.0      1.4      0.4          if max_depth is not None and max_depth <= 0:\n",
      "   257                                                       return rows\n",
      "   258                                           \n",
      "   259     15046      22091.0      1.5      0.9          for measurement in nonlocal_measurements:\n",
      "   260      7522      11883.0      1.6      0.5              if measurement.tag not in _MEASUREMENT_TYPES:\n",
      "   261                                                           raise NotImplementedError(\n",
      "   262                                                               '{}: measurement type \"{}\" not recognized:\\nattributes={}\\nsubnodes={}'\n",
      "   263                                                               .format(self._db_path, measurement.tag, measurement.attrib,\n",
      "   264                                                                       [_ for _ in measurement]))\n",
      "   265                                           \n",
      "   266      7522      12507.0      1.7      0.5              if self._skip_callsite and measurement.tag == 'C':\n",
      "   267      1216       1796.0      1.5      0.1                  rows += self._add_measurements(measurement, location,\n",
      "   268      1216       1933.0      1.6      0.1                                                 max_depth=max_depth, add_local=False)\n",
      "   269      1216       1640.0      1.3      0.1                  continue\n",
      "   270                                           \n",
      "   271      6306       9207.0      1.5      0.4              new_location = {}\n",
      "   272      6306      12025.0      1.9      0.5              new_location.update(location)\n",
      "   273     50448      74982.0      1.5      3.1              for (attrib, field), transformer in _LOCATION_DATA_TRANSFORMERS.items():\n",
      "   274     44142      65664.0      1.5      2.7                  if attrib not in measurement.attrib:\n",
      "   275     19256      25633.0      1.3      1.1                      continue\n",
      "   276     24886      34723.0      1.4      1.4                  if field is None:\n",
      "   277     19560      27944.0      1.4      1.2                      field = _LOCATION_TYPES[attrib]\n",
      "   278     24886      71855.0      2.9      3.0                  new_location[field] = transformer(self, measurement.attrib[attrib])\n",
      "   279                                           \n",
      "   280      6306       8940.0      1.4      0.4              assert 'id' in new_location, \\\n",
      "   281                                                           (measurement.tag, measurement.attrib, [_ for _ in measurement])\n",
      "   282      6306      10063.0      1.6      0.4              new_location['type'] = _MEASUREMENT_TYPES[measurement.tag]\n",
      "   283      6306      12819.0      2.0      0.5              new_location['callpath'] = (*location['callpath'], new_location['id'])\n",
      "   284                                           \n",
      "   285      6306       9681.0      1.5      0.4              rows += self._add_measurements(\n",
      "   286      6306       9144.0      1.5      0.4                  measurement, new_location, max_depth=None if max_depth is None else max_depth - 1,\n",
      "   287      6306      10056.0      1.6      0.4                  add_local=True)\n",
      "   288                                           \n",
      "   289      7524       9806.0      1.3      0.4          return rows\n",
      "\n",
      "Total time: 0.005902 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: _fix_root_measurement at line 291\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   291                                               def _fix_root_measurement(self):\n",
      "   292         2        551.0    275.5      9.3          pattern = re.compile(r'(?P<prefix>.+:.+) \\(E\\)')\n",
      "   293         2          2.0      1.0      0.0          column_pairs = []\n",
      "   294        64        156.0      2.4      2.6          for target_column in self.columns:\n",
      "   295        62        114.0      1.8      1.9              match = pattern.fullmatch(target_column)\n",
      "   296        62         48.0      0.8      0.8              if match is None:\n",
      "   297        40         19.0      0.5      0.3                  continue\n",
      "   298        22         37.0      1.7      0.6              source_column = '{} (I)'.format(match['prefix'])\n",
      "   299        22        155.0      7.0      2.6              if source_column in self.columns:\n",
      "   300        22         20.0      0.9      0.3                  column_pairs.append((target_column, source_column))\n",
      "   301        22         14.0      0.6      0.2                  continue\n",
      "   302                                                       _LOG.warning('%s: no target column \"%s\" found for \"%s\", cannot fix root measurement',\n",
      "   303                                                                    self._db_path, target_column, source_column)\n",
      "   304        24         27.0      1.1      0.5          for target_column, source_column in column_pairs:\n",
      "   305        22       4759.0    216.3     80.6              self.at[_ROOT_INDEX, target_column] = self.at[_ROOT_INDEX, source_column]\n",
      "\n",
      "Total time: 0.001393 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: _determine_percentage_column_base at line 307\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   307                                               def _determine_percentage_column_base(self, columns) -> str:\n",
      "   308         2          2.0      1.0      0.1          percentage_column = None\n",
      "   309         4          5.0      1.2      0.4          for candidate in self._percentage_column_candidates:\n",
      "   310         3          5.0      1.7      0.4              col = self._fundamental_column_prefix + candidate\n",
      "   311         3          4.0      1.3      0.3              if col in columns:\n",
      "   312         1          1.0      1.0      0.1                  percentage_column = col\n",
      "   313         1          1.0      1.0      0.1                  break\n",
      "   314         2          2.0      1.0      0.1          if percentage_column is None:\n",
      "   315         1         61.0     61.0      4.4              unique_prefixes = list(ordered_set.OrderedSet(_.partition(':')[0] for _ in columns))\n",
      "   316         1          1.0      1.0      0.1              _LOG.warning(\n",
      "   317         1          1.0      1.0      0.1                  '%s: percentage column candidates %s%s not found, trying %s:%s', self._db_path,\n",
      "   318         1          1.0      1.0      0.1                  self._fundamental_column_prefix, self._percentage_column_candidates,\n",
      "   319         1       1296.0   1296.0     93.0                  unique_prefixes, self._percentage_column_candidates)\n",
      "   320         1          2.0      2.0      0.1              for prefix in unique_prefixes:\n",
      "   321         1          2.0      2.0      0.1                  for candidate in self._percentage_column_candidates:\n",
      "   322         1          3.0      3.0      0.2                      col = '{}:{}'.format(prefix, candidate)\n",
      "   323         1          2.0      2.0      0.1                      if col in columns:\n",
      "   324         1          0.0      0.0      0.0                          percentage_column = col\n",
      "   325         1          1.0      1.0      0.1                          break\n",
      "   326         1          0.0      0.0      0.0                  if percentage_column is not None:\n",
      "   327         1          1.0      1.0      0.1                      break\n",
      "   328         2          2.0      1.0      0.1          assert percentage_column is not None, columns\n",
      "   329         2          0.0      0.0      0.0          return percentage_column\n",
      "\n",
      "Total time: 10.7709 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: _add_percentage_columns at line 331\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   331                                               def _add_percentage_columns(\n",
      "   332                                                       self, columns_and_methods: t.Sequence[t.Tuple[str, str]] = None) -> None:\n",
      "   333         2          2.0      1.0      0.0          if columns_and_methods is None:\n",
      "   334         2          2.0      1.0      0.0              base_column = self._meaningful_columns['percentage']\n",
      "   335         2          2.0      1.0      0.0              columns_and_methods = ((base_column, 'total'), (base_column, 'parent'))\n",
      "   336         6          6.0      1.0      0.0          for base_column, method in columns_and_methods:\n",
      "   337         4          5.0      1.2      0.0              self.add_ratio_column(\n",
      "   338         4   10770849.0 2692712.2    100.0                  base_column, '{} ratio of {}'.format(base_column, method), method)\n",
      "\n",
      "Total time: 10.6706 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: add_ratio_column at line 340\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   340                                               def add_ratio_column(self, base_column: str, column_name: str, method: str) -> None:\n",
      "   341                                                   \"\"\"Add a new column with ratio information taken from the base column.\n",
      "   342                                           \n",
      "   343                                                   There are two methods of calculating the ratios.\n",
      "   344                                           \n",
      "   345                                                   \"total\"\n",
      "   346                                                   Compare all values in the base column to the value in that column at the root.\n",
      "   347                                           \n",
      "   348                                                   \"parent\"\n",
      "   349                                                   Compare each value in the base column to the value in that column\n",
      "   350                                                   at one level higher in the call path.\n",
      "   351                                                   \"\"\"\n",
      "   352         4         81.0     20.2      0.0          assert base_column in self.columns, (base_column, self.columns)\n",
      "   353         4         14.0      3.5      0.0          assert column_name not in self.columns, (column_name, self.columns)\n",
      "   354         4         26.0      6.5      0.0          column_index = self.columns.get_loc(base_column) + 1\n",
      "   355         4      10177.0   2544.2      0.1          simple_self = self[[base_column, 'callpath']]\n",
      "   356         4          6.0      1.5      0.0          if method == 'total':\n",
      "   357         2       2581.0   1290.5      0.0              filtered = simple_self.loc[[_ROOT_INDEX]]\n",
      "   358         2        242.0    121.0      0.0              total = filtered[base_column].item()\n",
      "   359         2    1805843.0 902921.5     16.9              data = [row.at[base_column] / total for _, row in simple_self.iterrows()]\n",
      "   360                                                   else:\n",
      "   361         2          2.0      1.0      0.0              assert method == 'parent'\n",
      "   362         2          3.0      1.5      0.0              data = []\n",
      "   363         2          2.0      1.0      0.0              _cache = {}\n",
      "   364      6310    1681521.0    266.5     15.8              for _, row in simple_self.iterrows():\n",
      "   365      6308     248582.0     39.4      2.3                  value = row.at[base_column]\n",
      "   366      6308     211406.0     33.5      2.0                  base_callpath = row.at['callpath']\n",
      "   367      6308       8711.0      1.4      0.1                  base = None\n",
      "   368      9984      12413.0      1.2      0.1                  while base is None or base < value:\n",
      "   369      6308      10181.0      1.6      0.1                      base_callpath = base_callpath[:-1]\n",
      "   370      6308       9104.0      1.4      0.1                      if base_callpath in _cache:\n",
      "   371      2632       3481.0      1.3      0.0                          base = _cache[base_callpath]\n",
      "   372      2632       2905.0      1.1      0.0                          break\n",
      "   373      3676       3826.0      1.0      0.0                      try:\n",
      "   374      3676    6241328.0   1697.9     58.5                          filtered = simple_self.loc[simple_self['callpath'] == base_callpath]\n",
      "   375                                                               except KeyError:\n",
      "   376                                                                   _LOG.exception('%s: no measurements for callpath %s',\n",
      "   377                                                                                  self._db_path, base_callpath)\n",
      "   378                                                                   continue\n",
      "   379      3676      14575.0      4.0      0.1                      assert len(filtered) == 1, \\\n",
      "   380                                                                   (base_column, row.at['callpath'], base_callpath, filtered)\n",
      "   381      3676     379740.0    103.3      3.6                      base = filtered[base_column].item()\n",
      "   382      3676       7137.0      1.9      0.1                      _cache[base_callpath] = base\n",
      "   383      6308       9662.0      1.5      0.1                  data.append(value / base)\n",
      "   384         2        282.0    141.0      0.0              del _cache\n",
      "   385         4       6786.0   1696.5      0.1          self.insert(column_index, column_name, data)\n",
      "\n",
      "Total time: 3.31423 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: at_paths at line 391\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   391                                               def at_paths(self, *fragments, prefix: tuple = (), suffix: tuple = ()) -> pd.DataFrame:\n",
      "   392        37    3269143.0  88355.2     98.6          mask = self.apply(_callpath_filter, axis=1, args=(fragments, prefix, suffix))\n",
      "   393        37      45083.0   1218.5      1.4          return self[mask]\n",
      "\n",
      "Total time: 10.6531 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: at_depths at line 395\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   395                                               def at_depths(self, min_depth: t.Optional[int] = None,\n",
      "   396                                                             max_depth: t.Optional[int] = None) -> pd.DataFrame:\n",
      "   397        84   10542566.0 125506.7     99.0          mask = self.apply(_depth_filter, axis=1, args=(min_depth, max_depth))\n",
      "   398        84     110531.0   1315.8      1.0          return self[mask]\n",
      "\n",
      "Total time: 10.654 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: at_depth at line 400\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   400                                               def at_depth(self, depth: int) -> pd.DataFrame:\n",
      "   401        84   10653983.0 126833.1    100.0          return self.at_depths(depth, depth)\n",
      "\n",
      "Total time: 5.58793 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: hot_path at line 403\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   403                                               def hot_path(self, callpath: t.Sequence[int] = (), threshold: int = 0.05,\n",
      "   404                                                            base_column: str = None) -> pd.DataFrame:\n",
      "   405         2          4.0      2.0      0.0          if base_column is None:\n",
      "   406         2          4.0      2.0      0.0              base_column = self._meaningful_columns['hot_path']\n",
      "   407         2         20.0     10.0      0.0          assert base_column in self.columns, (base_column, self.columns)\n",
      "   408         2       8156.0   4078.0      0.1          simple_self = self[[base_column, 'callpath']]\n",
      "   409         2          3.0      1.5      0.0          hot_callpaths = []\n",
      "   410                                           \n",
      "   411         2          2.0      1.0      0.0          while True:\n",
      "   412        35         59.0      1.7      0.0              hot_callpaths.append(callpath)\n",
      "   413                                           \n",
      "   414        35    2973163.0  84947.5     53.2              simple_self = simple_self.at_paths(prefix=callpath)\n",
      "   415        35        479.0     13.7      0.0              _LOG.debug('%s: %i at target callpath', self._db_path, len(simple_self))\n",
      "   416        35    2558037.0  73086.8     45.8              at_depth = simple_self.at_depth(len(callpath) + 1)\n",
      "   417        35        466.0     13.3      0.0              _LOG.debug('%s: %i at depth %i', self._db_path, len(at_depth), len(callpath) + 1)\n",
      "   418                                           \n",
      "   419        35        540.0     15.4      0.0              if at_depth.empty:\n",
      "   420         2          2.0      1.0      0.0                  break\n",
      "   421                                           \n",
      "   422        33      12545.0    380.2      0.2              hottest_index = at_depth[base_column].idxmax()\n",
      "   423        33      25345.0    768.0      0.5              hottest_row = simple_self.loc[hottest_index]\n",
      "   424        33       1522.0     46.1      0.0              callpath = hottest_row.at['callpath']\n",
      "   425        33       1325.0     40.2      0.0              if hottest_row.at[base_column] < threshold:\n",
      "   426                                                           break\n",
      "   427                                           \n",
      "   428         2       6254.0   3127.0      0.1          return self[self.callpath.isin(hot_callpaths)]\n",
      "\n",
      "Total time: 20.0075 s\n",
      "File: /home/mateusz/Projects/hpctoolkit_dataframe/hpctoolkit_dataframe/hpctoolkit_dataframe.py\n",
      "Function: flame_graph at line 430\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   430                                               def flame_graph(\n",
      "   431                                                       self, prefix=(), column='CPUTIME (usec):Mean (I) ratio of parent',\n",
      "   432                                                       min_depth=None, max_depth=None,\n",
      "   433                                                       shape: str = 'rect', style: str = 'flame', highlight=None):\n",
      "   434                                                   \"\"\"Stack trace graph.\n",
      "   435                                           \n",
      "   436                                                   shape: 'rect' or 'wheel'\n",
      "   437                                                   style: 'flame', 'skyline', 'mountains'\n",
      "   438                                                   \"\"\"\n",
      "   439         2     800750.0 400375.0      4.0          import matplotlib.pyplot as plt\n",
      "   440         2          9.0      4.5      0.0          if min_depth is None:\n",
      "   441         2          8.0      4.0      0.0              min_depth = len(prefix) + 1\n",
      "   442         2          7.0      3.5      0.0          assert min_depth > len(prefix), min_depth\n",
      "   443         2          7.0      3.5      0.0          assert shape in {'rect', 'wheel'}, shape\n",
      "   444         2          8.0      4.0      0.0          if style == 'flame':\n",
      "   445         2         14.0      7.0      0.0              color_map = plt.get_cmap('autumn')\n",
      "   446         2          8.0      4.0      0.0              colors = lambda n: color_map(np.linspace(0, 1, n))\n",
      "   447                                                   elif style == 'skyline':\n",
      "   448                                                       color_map = plt.get_cmap('YlGnBu')\n",
      "   449                                                       colors = lambda n: color_map(np.linspace(0, 1, n))\n",
      "   450                                                   elif style == 'mountains':\n",
      "   451                                                       color_map = plt.get_cmap('Greys')\n",
      "   452                                                       colors = lambda n: color_map(np.linspace(0, 1, n))\n",
      "   453                                                   else:\n",
      "   454                                                       color_map = plt.get_cmap('tab20c')\n",
      "   455                                                       colors = lambda n: color_map(np.arange(n))\n",
      "   456         2      53062.0  26531.0      0.3          fig, ax = plt.subplots(subplot_kw=dict(polar=shape == 'wheel'), figsize=(16, 16))\n",
      "   457         2         10.0      5.0      0.0          thickness = 1\n",
      "   458                                           \n",
      "   459         2          7.0      3.5      0.0          at_depth = {}\n",
      "   460                                           \n",
      "   461         2     341947.0 170973.5      1.7          base = self.at_paths(prefix=prefix)\n",
      "   462                                           \n",
      "   463                                                   # for depth in range(min_depth, max_depth + 1):\n",
      "   464         2          9.0      4.5      0.0          depth = min_depth\n",
      "   465        49        170.0      3.5      0.0          while max_depth is None or depth <= max_depth:\n",
      "   466        49        614.0     12.5      0.0              _LOG.info('at depth %i', depth)\n",
      "   467        49        205.0      4.2      0.0              at_depth[depth] = {}\n",
      "   468        49    8096908.0 165243.0     40.5              df = base.at_depth(depth)\n",
      "   469        49        231.0      4.7      0.0              at_depth[depth]['df'] = df\n",
      "   470        49        910.0     18.6      0.0              if df.empty:\n",
      "   471         2         10.0      5.0      0.0                  break\n",
      "   472                                           \n",
      "   473        47       5762.0    122.6      0.0              ids = at_depth[depth]['df']['id'].values\n",
      "   474        47        575.0     12.2      0.0              _LOG.info('ids:  %s', ids)\n",
      "   475        47       4663.0     99.2      0.0              raw_values = at_depth[depth]['df'][column].values\n",
      "   476        47        435.0      9.3      0.0              _LOG.debug('raw:  %s', raw_values)\n",
      "   477                                           \n",
      "   478        47        197.0      4.2      0.0              if depth - 1 in at_depth:\n",
      "   479                                                           # normalize data to previous layer\n",
      "   480        45       5107.0    113.5      0.0                  by_parent = {}\n",
      "   481      6349    1663979.0    262.1      8.3                  for i, (_, series) in enumerate(at_depth[depth]['df'].iterrows()):\n",
      "   482      6304     370527.0     58.8      1.9                      callpath = series['callpath']\n",
      "   483      6304      26193.0      4.2      0.1                      parent = callpath[-2]\n",
      "   484      6304      24170.0      3.8      0.1                      if parent not in by_parent:\n",
      "   485      3674      14702.0      4.0      0.1                          by_parent[parent] = []\n",
      "   486      6304      26146.0      4.1      0.1                      by_parent[parent].append((i, series))\n",
      "   487        45        194.0      4.3      0.0                  _LOG.debug('by parent: %s', {_: [i for i, series in items]\n",
      "   488        45       6337.0    140.8      0.0                                               for _, items in by_parent.items()})\n",
      "   489                                           \n",
      "   490        45        833.0     18.5      0.0                  normalized_values = []\n",
      "   491        45        207.0      4.6      0.0                  offsets = []\n",
      "   492      3719      17362.0      4.7      0.1                  for parent, items in by_parent.items():\n",
      "   493      3674      19849.0      5.4      0.1                      ratio = at_depth[depth - 1]['widths'][parent] / _NORMALIZATION_CONSTANT\n",
      "   494      3674      33836.0      9.2      0.2                      raw_items = np.array([raw_values[i] for i, _ in items])\n",
      "   495      3674      94316.0     25.7      0.5                      normalized_items = raw_items / np.sum(raw_items) * _NORMALIZATION_CONSTANT * ratio\n",
      "   496      3674      25207.0      6.9      0.1                      normalized_values += list(normalized_items)\n",
      "   497                                           \n",
      "   498      3674      18436.0      5.0      0.1                      base_offest = at_depth[depth - 1]['offsets'][parent]\n",
      "   499      3674      89854.0     24.5      0.4                      items_offsets = np.append(0, normalized_items.cumsum()[:-1]) + base_offest\n",
      "   500      3674      15908.0      4.3      0.1                      assert len(normalized_items) == len(items_offsets)\n",
      "   501      3674      23073.0      6.3      0.1                      offsets += list(items_offsets)\n",
      "   502        45       1103.0     24.5      0.0                  widths = np.array(normalized_values)\n",
      "   503        45       1602.0     35.6      0.0                  offsets = np.array(offsets)\n",
      "   504        45        186.0      4.1      0.0                  assert len(widths) == len(offsets)\n",
      "   505                                                       else:\n",
      "   506         2         82.0     41.0      0.0                  widths = raw_values / np.sum(raw_values) * _NORMALIZATION_CONSTANT\n",
      "   507         2         16.0      8.0      0.0                  _LOG.debug('norm const: %f', _NORMALIZATION_CONSTANT)\n",
      "   508         2         65.0     32.5      0.0                  offsets = np.append(0, widths.cumsum()[:-1])\n",
      "   509        47        204.0      4.3      0.0              at_depth[depth]['offsets'] = collections.OrderedDict(\n",
      "   510        47       4537.0     96.5      0.0                  [(id_, _) for id_, _ in zip(ids, offsets)])\n",
      "   511        47        470.0     10.0      0.0              _LOG.info('offsets: %s', offsets)\n",
      "   512                                           \n",
      "   513        47        186.0      4.0      0.0              at_depth[depth]['widths'] = collections.OrderedDict(\n",
      "   514        47       3826.0     81.4      0.0                  [(id_, _) for id_, _ in zip(ids, widths)])\n",
      "   515        47        358.0      7.6      0.0              _LOG.info('widths: %s', widths)\n",
      "   516                                           \n",
      "   517        47        198.0      4.2      0.0              y = (depth - min_depth + 1) * thickness\n",
      "   518        47        194.0      4.1      0.0              ax.bar(\n",
      "   519        47        163.0      3.5      0.0                  x=offsets, width=widths, bottom=y, height=thickness,\n",
      "   520        47    7764046.0 165192.5     38.8                  color=colors(len(offsets)), edgecolor='w', linewidth=1, align='edge')\n",
      "   521                                           \n",
      "   522      6353      25122.0      4.0      0.1              for i, id_ in enumerate(ids):\n",
      "   523      6306      27861.0      4.4      0.1                  if widths[i] < np.pi / (depth - min_depth + 32):\n",
      "   524      6046      21846.0      3.6      0.1                      continue\n",
      "   525       260       1501.0      5.8      0.0                  x = offsets[i] + widths[i] / 2\n",
      "   526       260        988.0      3.8      0.0                  if shape == 'wheel':\n",
      "   527                                                               rotation = x * 180 / np.pi - 90\n",
      "   528                                                           else:\n",
      "   529       260        919.0      3.5      0.0                      rotation = 0\n",
      "   530                                                           # text = str(id_)\n",
      "   531       260     181485.0    698.0      0.9                  text = self.loc[id_]['procedure']\n",
      "   532       260       1155.0      4.4      0.0                  ax.text(\n",
      "   533       260       1061.0      4.1      0.0                      x=x, y=y + thickness * 0.2, s=text,\n",
      "   534       260        933.0      3.6      0.0                      rotation=rotation,\n",
      "   535       260     165948.0    638.3      0.8                      horizontalalignment='center', verticalalignment='center')\n",
      "   536        47        171.0      3.6      0.0              depth += 1\n",
      "   537                                           \n",
      "   538         2        896.0    448.0      0.0          ax.set(title=self._db_path.name)\n",
      "   539         2         23.0     11.5      0.0          ax.set_axis_off()\n",
      "   540         2      17609.0   8804.5      0.1          plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling ways to query a DataFrame (obsolete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "`DataFrame.loc[[str(...)]]` vs `DataFrame[DataFrame.col == ...]` vs `DataFrame[DataFrame['col'] == ...]`\n",
    "\n",
    "assuming that `DataFrame` is indexed by stringified column `col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579 µs ± 34.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df.loc[[str(())]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hpctoolkit_dataframe.HPCtoolkitDataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[[str(())]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544 µs ± 36.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df[df.location == ()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hpctoolkit_dataframe.HPCtoolkitDataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[df.location == ()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529 µs ± 36.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df[df['location'] == ()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "`Series.at[...]` vs `Series.get(...)` vs `Series[...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df.loc['()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 µs ± 1.68 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df.loc['()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.71 µs ± 56.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "filtered.at['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered.at['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.82 µs ± 256 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "filtered.get('location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered.get('location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4 µs ± 23.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "filtered['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered['location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "`DataFrame.at['index', 'col']` vs `DataFrame.get('col').item()` vs `DataFrame['col'].item()`\n",
    "\n",
    "assuming that `Dataframe` contains only one row (indexed as `'index'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df.loc[['()']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hpctoolkit_dataframe.HPCtoolkitDataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522 µs ± 5.37 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df.loc[['()']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.69 µs ± 55.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "filtered.at['()', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered.at['()', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61 µs ± 104 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "filtered.get('location').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered.get('location').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.43 µs ± 34.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "filtered['location'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered['location'].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
